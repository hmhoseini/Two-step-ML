\begin{longtable}{|l|>{\columncolor{bestColumnColor}}l|l|l|l|l|}
\hline
\textbf{parameter name} & \multicolumn{5}{c|}{\textbf{best values}} \\
\hline
\textit{training time avg} &  55.489 &  62.251 &  92.568 &   96.35 \\
{\color{equalParamColor} neurons per layer } & {\color{equalParamColor} (50, 10) } & {\color{equalParamColor} (50, 10) } & {\color{equalParamColor} (50, 10) } & {\color{equalParamColor} (50, 10) } \\
{\color{equalParamColor} activation functions } & {\color{equalParamColor} ReLU } & {\color{equalParamColor} ReLU } & {\color{equalParamColor} ReLU } & {\color{equalParamColor} ReLU } \\
last activation function & sigmoid & softmax & sigmoid & softmax \\
{\color{equalParamColor} loss function } & {\color{equalParamColor} cat-cross } & {\color{equalParamColor} cat-cross } & {\color{equalParamColor} cat-cross } & {\color{equalParamColor} cat-cross } \\
{\color{equalParamColor} training data percentage } & {\color{equalParamColor} 1.0 } & {\color{equalParamColor} 1.0 } & {\color{equalParamColor} 1.0 } & {\color{equalParamColor} 1.0 } \\
{\color{equalParamColor} number of epochs } & {\color{equalParamColor} 250 } & {\color{equalParamColor} 250 } & {\color{equalParamColor} 250 } & {\color{equalParamColor} 250 } \\
{\color{equalParamColor} batch size } & {\color{equalParamColor} 100 } & {\color{equalParamColor} 100 } & {\color{equalParamColor} 100 } & {\color{equalParamColor} 100 } \\
optimizer                & Adam    & Adam    & my Adam & my Adam \\
{\color{equalParamColor} learning rate } & {\color{equalParamColor} 0.001 } & {\color{equalParamColor} 0.001 } & {\color{equalParamColor} 0.001 } & {\color{equalParamColor} 0.001 } \\
{\color{equalParamColor} $\varepsilon$ } & {\color{equalParamColor} $10^{-7}$ } & {\color{equalParamColor} $10^{-7}$ } & {\color{equalParamColor} $10^{-7}$ } & {\color{equalParamColor} $10^{-7}$ } \\
\hline

\caption{best settings regarding \textit{training time avg} for the cadam variants dataset}
\label{table:variant_training_time_avg_best_cadam_variants}
\end{longtable}
